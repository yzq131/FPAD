# FPAD
Deep cross-modal hashing models generally inherit the vulnerabilities of deep neural networks, making them susceptible to adversarial attacks and thus posing a serious security risk during real-world deployment. 
Current adversarial attack or defense strategies often establish a weak correlation between the hashing codes and the targeted semantic representations, and there is a lack of related works that  simultaneously consider the attack and defense for deep cross-modal hashing. 
Additionally,  these strategies are inadequate in producing cross-modal adversarial examples that significantly enhance the model robustness throughout the training process. 
To alleviate these concerns, we propose a Fuzzy-Prototype-guided Adversarial Attack and Defense (FPAD) framework to enhance the adversarial robustness of deep cross-modal hashing models.
# We will release our code soon...
